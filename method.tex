
\section{Our approach}
\label{sec:method}

Our algorithm \algo{} uses a linear programming rounding technique, combined with the sample average approximation
technique from stochastic optimization. We then show that this can be significantly speeded up by a more compact LP.

\subsection{Algorithm \algo{}}

%%We start with some definitions needed for the algorithm. Let $H_j=(V, E_j)$ denote a random subgraph of $G$,
%%where each edge $e\in E$ is selected to be in $E_j$ with probability $p$. 
%%Let $\src^{(j)}$ denote the set of source nodes in $H_j$, and
%%let $\mathcal{P}_{vj}$ be the set of paths from sources to $v$ in $H_j$. 
%%Let $N_{vj} = |\mathcal{P}_{vj}|$ be the number of paths from any source to $v$ in $H_j$. 
%%Let $N = max_{(v,j)}  N_{vj}$ be the maximum number of paths from sources to a node in any of the sampled
%%graphs. Let $y_{vj}$ denote the indicator variable to check whether node $v$ is reachable from any source in $H_j$.
%%As defined earlier, $x_{vt}$ is the indicator that node $v$ is vaccinated at time $t$.


\begin{algorithm}{}
\small
\caption{\small $\algo{}$\\
\textbf{Input:} $G, \src, \mathcal{T}, B_t$ for $t\in\mathcal{T}$\\
\textbf{Output:} $\X=\{\X_t: t\in\mathcal{T}\}$
}
\label{alg:saaround}
\begin{algorithmic}[1]
\STATE
Construct a sampled graph $H_j=(V, E_j)$, for $j=1,\ldots,H_M$, by picking each edge $e\in E$ to be in $E_j$
with probability $p$. Also pick a set of sources $\ssrc(H_j)$ by sampling from $\src$
\STATE
Run breadth first search (BFS) in each $H_j$ from the nodes in $\ssrc(H_j)$.
Let $V_{j,t}$ denote the set of all nodes at level $t$ in the BFS tree in $H_j$ 
(with the nodes in $\ssrc(H_j)$ at level $0$); let $V_{j,\geq t}=\cup_{t'\geq t} V_{j,t}$ denote
the set of all nodes at level $t$ or more.
\STATE
Solve the following linear program ($LP_{saa}$)
\begin{eqnarray}
\label{eqn:obj}
(LP_{saa}) \qquad  \min \frac{1}{M}\sum_j \sum_v y_{vj} && \\
\label{eqn:xy}
\forall u \in V_{j, \geq t} - \ssrc(H_j), \forall t:\ y_{uj} &\leq& 1 - x_{ut} \\
\label{eqn:xy2}
\forall u \in \ssrc(H_j):\ y_{uj} &\leq& 1 - x_{u0} \\
\label{eqn1}
\forall j, \forall u\in V, \; (w, u)\in E_j:\ y_{uj} &\geq& y_{wj} - \sum_{t: u \in V_{j, \geq t}} x_{ut}\\
\label{eqn:src}
\forall j, \forall s \in src(H_j):\ y_{sj} &=& 1\\
\label{eqn:budget}
\forall t\in\mathcal{T}:\ \sum_u x_{ut} &\leq& B_t\\
%\label{eqn:uniqt}
%\forall u,\ \sum_t x_{ut} &\leq& 1\\
\label{eqn01}
\mbox{All variables} &\in& [0, 1]
\end{eqnarray}
\STATE
Let $x, y$ be the optimal fractional solution to (LP).
We round it to an integral solution in the following manner
\begin{enumerate}
\item
Round $Y_{vj} = 1$ for each $(v,j)$ if $y_{vj} \geq \frac{1}{2}$, otherwise set $Y_{vj} = 0$.
\item
For each $v, t$, set $X_{vt}=1$ with probability $\min\{1, 2 x_{vt}\log(4nMN)\}$. 
\item
$X_t=\{v: X_{vt}=1\}$ is the set of nodes vaccinated at time $t$, and $X=\cup_t X_t$
is the total set of vaccinated nodes.
\end{enumerate}
\STATE \textbf{return} $X$
\end{algorithmic}
\end{algorithm}

\noindent
\textbf{Intuition behind \algo{} and its analysis.}
Our algorithm involves four key ideas, which are described below, along with an intuitive description of
the steps of the algorithm.
\begin{itemize}[leftmargin=0.1in, noitemsep, topsep=0pt]
\item
Sample average approximation technique: 
The first idea is that it suffices to get a solution which minimizes the average number of
infections in a set of $M$ sampled outcomes, in order to minimize $\expinf(\cdot)$, which is an expectation
over all possible outcomes; we show that it suffices to $M$ is bounded by a polynomial in $n$.
Further, instead of actually using simulation outcomes, Steps 1 and 2 exploit an equivalence between an
SIR process and percolation, making this much more efficient.
\item
Compact integer program:
The problem is challenging even if we have to minimize the average number of infections restricted to
$H_1,\ldots,H_M$. We start with an integer program (IP) which expresses the following constraints: if a node $u$ is not infected in $H_j$
(which is indicated by $y_{uj}=0$), then for every path $P$ from a node in $\ssrc(H_j)$ to $u$ in $H_j$, there must be
a node $v$ which has been vaccinated. Further, node $v$ must have been vaccinated at a time $t< length(P)$, otherwise the
vaccination would not be effective. 
However, such an integer program would have exponentially many constraints (one for each path).
Instead, we design a more compact program,
simply based on states of nodes on an edge, as expressed in constraints (\ref{eqn1}).
This IP is an  integral version of $LP_{saa}$, with the variables required to be binary
which we prove is equivalent.
\item
Linear relaxation:
IP cannot be solved in polynomial time, and we consider a linear relaxation of it, by replacing the binary constraints
by (\ref{eqn01}). The resulting program $LP_{saa}$ involves minimizing a linear objective over a convex polytope,
and so step 3 of \algo{} can be done efficiently to compute the fractional solutions $x, y$.
Also note that since $LP_{saa}$ is optimizing over a larger space (specifically, the convex hull of all the
feasible integral solutions), the objective value in (\ref{eqn:obj}) might be smaller than the integral objective value.
\item
Rounding to an integral solution:
The solution $x$ is fractional, which poses a problem:
if we have $x_{ut}\in(0, 1)$, e.g., a fractional value of $0.2$, it is not clear how to construct
a valid integral solution. In Step 4(1) of \algo{}, we pick all the nodes with $y_{uj}\leq 1/2$ (denoted by $Y_{uj}=0$),
and pick a set of nodes to vaccinate (Step 4(2)), such that every node $u$ with $Y_{uj}=0$ gets disconnected from $\ssrc(H_j)$.
Step 4(2) achieves this by rounding the fractional solution $x$, after appropriate scaling.
This randomized rounding step ensures that the budgets are not violated by much.
This also implies that any node $u$ which gets infected in $H_j$ has $y_{uj}>1/2$, so that the average number
of infections can be bounded by at most twice the fractional objective value.
\end{itemize}

We first start by showing that $LP_{saa}$ is indeed valid, which is not apparent from its structure

\begin{lemma}
The constraints of $LP_{saa}$ are valid.
\end{lemma}
\begin{proof} (Sketch)
Our proof involves showing that the constraints (\ref{eqn:xy}), (\ref{eqn:xy2}), (\ref{eqn1}),
(\ref{eqn:src}), and (\ref{eqn:budget}) are valid, i.e., they are satisfied by an optimal solution.
Consider an optimal solution $\X^*=\{\X^*_t, t\in\mathcal{T}\}$ for the set of sampled graphs
$H_1,\ldots,H_M$. It will follow from Lemma \ref{lemma:conc} later that $\X^*$ is also ``close to''
an optimal integral solution to the $\expinf$ objective itself.
We define $x^*_{ut}=1$ if $u\in\X^*_t$, and $y^*_{vj}=1$ if node $v$ gets infected in $H_j$, i.e.,
there is a path connecting a node in $\ssrc(H_j)$ to $v$, even after all nodes in $\cup_{t\leq dist(\ssrc(H_j), v)} X^*_t$ are 
removed.
This is encoded in the constraints (\ref{eqn1}) for the following reason. 
Consider a node $u$ such that $y_{uj}=0$. From the above discussion, it must follow that on every path $P$ from
$\ssrc(H_j)$ to $u$, some node $v$ must get vaccinated in time, i.e., within $t\leq dist(\ssrc(H_j), v)$.
Consider the predecessor node $w$ of $u$ on path $P$. If we have $y_{wj}=0$, some node on the sub-path $P'$ of $P$
ending in $w$ would have a vaccinated node. Otherwise, $w$ is infected in $H_j$, and the only way $u$ will not be
infected is if $x_{ut}=1$ for some $u$.
\end{proof}

\begin{lemma}
\label{lem:disconnect}
For any $H_j$, and any node $v\in V$ with $y_{vj} < \frac{1}{2}$, we have
\[
\Pr[\mbox{$v$ is reachable from $\ssrc(H_j)$ in $H_j[V-\X]$}] < \frac{1}{4nM}
\]
where $H_j[V-\X]$ is the graph induced by removing the nodes in $\X$ from $H_j$.
\end{lemma}
\begin{proof} (Sketch)
Let $\mathcal{P}_{vj} = \{P_1, \ldots,P_L\}$ be the  set of paths to node $(v,j)$. 
For a path $P$, let $S(P)=\{(u, t): u\in P\cap V_{it}\}$.
If there exists $(u, t)\in S(P)$ with $2 x_{vt} \log(4nMN) \geq 1$, the rounding ensures that $X_{ut}=1$;
therefore, we only consider the case $2 x_{vt} \log(4nMN)\leq 1$.
Our rounding ensures that we have $\Pr[X_{ut}=1] \geq 2 x_{vt} \log(4nMN)$, so that
$\Pr[\sum_{u, t: u\in P\cap V_{it}} X_{ut} = 0]$ is upper bounded by
$\prod_{(u,t) \in S(P)} \big(1- 2 x_{ut} \log(4nMN)\big) \leq e^{-\sum_{(u, t)\in S(P)} 2 x_{ut} \log(4nMN)}
\leq e^{-\log(4nMN)}= \frac{1}{4nMN}$,
since $\sum_{(u, t)\in S(P)} x_{ut} \geq 1-y_{vj} \geq 1/2$.
Equivalently, the probability that no node from $S(P)$ is picked from $P$ is at most $\frac{1}{4nMN}$;
here we say a node is picked from $S(P)$ if $X_{u,t}=1$ for some $(u, t)\in S(P)$.
By a union bound, the probability that there exists a path $P_i$ such that no node from
$S(P_i)$ is picked is at most $\frac{L}{4nMN}\leq \frac{1}{4nM}$.
Finally, $v$ is reachable from $\ssrc(H_j)$ in $H_j[V-\X]$ if and only if there exists a path $P_i$ such that no node from
$S(P_i)$ is picked, and so the lemma follows.
\end{proof}

Next, we bound the violation in the budget constraints. We use the following Chernoff tail bound.

\begin{theorem} (Theorem 1.1 of \cite{books/daglib/0025902})
Let $Z=\sum_{i=1}^n Z_i$, where $Z_i$ are independently distributed random variables in $[0, 1]$. Then, for any $\epsilon\in(0, 1)$, we have
$\Pr[Z\not\in[(1-\epsilon)E[Z], (1+\epsilon)E[Z]]]\leq 2 exp(-\epsilon^2 E[Z]/3)$
\end{theorem}

\noindent
\begin{lemma}
\label{lem:budget}
With probability at least $1-1/n$, for each $t\in \mathcal{T}$, we have
$|X_t|\leq 4\log(4nMN)B_t$.
\end{lemma}
\begin{proof}
We have $E[\sum_u X_{ut}]\leq \sum_u 2x_{ut}\log(4nMN) \leq 2\log(4nMN)B_t$.
The $X_{ut}$'s are all rounded independently, and so we can apply the Chernoff bound on the sum, which gives
$\Pr[\sum_u X_{ut} > 4\log(4nMN)B_t] \leq exp(-2\log(4nMN)B_t) \leq exp(-2\log(4nMN))= \frac{1}{(4nMN)^2}\leq \frac{1}{16n^2}$.
The number of possible time steps in $\mathcal{T}$ is at most $n$, which implies that the probability that there exists 
$t\in\mathcal{T}$ such that $\sum_u X_{ut} > 4\log(4nMN)B_t$ is at most $n\frac{1}{16n^2}=\frac{1}{16n}\leq 1/n$.
\end{proof}

For a vaccination set $U$, let $Z_j(U)$ be the number of nodes in 
$H_j-U$, which are still reachable from $\ssrc(H_j)$;
note that this includes the sources themselves.
Let $Z(U)=\frac{1}{M}\sum_j Z_j(U)$, and let $\hat{X}_{opt}=\mbox{argmin}_{X'}Z(X')$ be the solution that
achieves the minimum average number of infections in the samples.
Finally, let $X_{opt}=\mbox{argmin}_{X'}\expinf(X')$ be the optimal solution to the $\prob{}$ instance,
The following lemma shows that the average number of infections achieved by a solution $U$ restricted to
the samples $H_1,\ldots,H_M$ is close to the $\expinf$ objective.

\begin{lemma}
\label{lemma:conc}
Let $Z(\cdot)$ be as defined above. If $M\geq 48n\log{n}$, with probability at least $1-1/n$, for every intervention set $U$,
we have $Z(U)\in [\frac{1}{2}\expinf(U), \frac{3}{2}\expinf(U)]$.
\end{lemma}
\begin{proof} (Sketch)
By definition, $Z(U)=\frac{1}{M}\sum_j Z_j(U)$.
We have $E[Z(U)] = E[Z_j(U)]=\expinf(U)$ for all $j$.
By the Chernoff bound, we have
\[
\Pr[MZ(U)\not\in [\frac{1}{2}, \frac{3}{2}]M\expinf(U)]\leq 2exp(-\frac{M}{24}\expinf(U))
\]
We have $\expinf(U)\geq 1$, since there is always at least one infection.
For $M=48n\log{n}$, this probability is at most $2e^{-2n\log{n}} = \frac{2}{e^2e^nn}$.
The number of possible intervention sets is the number of possible sets $U_t\subseteq V$, $t\in\mathcal{T}$,
which is at most $n2^n$.
Therefore, the probability that there exists an intervention set $U$ for which
$Z(U)\not\in [\frac{1}{2}, \frac{3}{2}]\expinf(U)$ is at most $n2^n\cdot \frac{2}{e^2e^nn}\leq \frac{1}{n}$.
\end{proof}

\begin{theorem}
\label{theorem:algo}
Let $X$ denote the vaccination set computed by algorithm \algo{}.
Then, with probability at least $1/2$, we have
$\expinf(X)\leq 6\expinf(X_{opt})$, and for all $t\in\mathcal{T}$, we have
$|X_t|\leq 4\log(4nMN)B_t$.
\end{theorem}
\begin{proof} (Sketch)
Let $\hat{X}_{opt}$ be as defined above. 
By Lemma \ref{lem:disconnect}, for any $v, j$, if $y_{vj} \leq 1/2$, the probability that node $v$ is
reachable from $\ssrc(H_j)$ is at most $\frac{1}{4nM}$.
By a union bound, the probability this does not hold for any $v$ (for a fixed $j$) is at most $\frac{1}{4M}$.
This implies that with probability at least $1-\frac{1}{4nM}$, 
\[
Z_j(X)\leq |\{v: y_{vj}\geq 1/2\}|\leq \sum_{v: y_{vj}\geq 1/2} 2y_{vj} \leq \sum_v 2y_{vj}
\]
By a union bound, with probability at least $1-\frac{M}{4M}=1-\frac{1}{4}$,
we have $Z_j(X)\leq 2\sum_v y_{vj}$, for all $j$.
By definition of $\hat{X}_{opt}$, we have $\frac{1}{M}\sum_j Z_j(X)\leq \frac{1}{M}\sum_{v,j} 2y_{vj} \leq 2Z(\hat{X}_{opt})$,
since the LP solution is also a lower bound on $Z(\hat{X}_{opt})$.
By Lemma \ref{lem:budget}, and a union bound, the condition $|X_t|\leq 4\log(4nMN)B_t$ holds for all $t$,
in addition to $Z(X)\leq 2Z(\hat{X}_{opt})\leq 2Z(X_{opt})$, with probability at least $1-\frac{1}{4}-\frac{1}{n}$,
since $Z(\hat{X}_{opt})\leq Z(X_{opt})$, by definition of $\hat{X}_{opt}$.

By Lemma \ref{lemma:conc}, with probability at least $1-\frac{1}{n}$,
we have $Z(X_{opt})\leq \frac{3}{2}\expinf(X_{opt})$, and
$\frac{1}{2}\expinf(X)\leq Z(X)$. This gives us
\[
\expinf(X)\leq 2Z(X)\leq 4Z(X_{opt})\leq 6\expinf(X_{opt})
\]
Therefore, all the conditions of the theorem hold with probability $\geq 1-\frac{1}{4}-\frac{2}{n}\geq \frac{1}{2}$.
\end{proof}


\subsection{Speeding up \algo{}}

The main bottleneck in \algo{} is the solution of $LP_{saa}$, which has: 
$nM$ variables of the form $y_{uj}$, $n|\mathcal{T}|$ variables of the form $x_{ut}$,
and $\sum_j |E(H_j)|$ constraints (\ref{eqn1}).
The worst case dependence of the running time of LP solvers is super-quadratic in these parameters
(though we find the Gurobi solver scales very well in practice, as we discuss later).
In order to improve the scaling of \algo{} to larger instances, we use the following methods.
\begin{itemize}
\item
Reduced number of samples: the rigorous bound on the number of samples needed in the worst case comes
from Lemma \ref{lemma:conc}, as a result of the Chernoff bound.
In practice, we find that there is concentration even with $O(\sqrt{n})$ samples, and so we
use fewer samples in our experiments. This can be estimated in a statistically rigorous manner by 
picking the smallest number of samples such that the variance is within a factor $\delta$.
\item
Reducing the number of variables: 
we define the \emph{vulnerability} of node $u$, denoted by $y_u$, as probability that it gets infected
(when no interventions are done).
This can be estimated as tthe fraction of samples $H_j$ in which $u$ is connected to $\ssrc(H_j)$,
i.e., $y_u=\frac{1}{M}|\{j: \mbox{$u$ is connected to $\ssrc(H_j)$}\}$.
For a parameter $\gamma$, we restrict the interventions to nodes in $V_{\gamma}=\{v: y_v > 1-\gamma\}$;
in other words, we can set $x_{vt}=0$ for nodes with vulnerability at most $\gamma$.
The intuition is that such nodes are likely to have low $x_{vt}$ values in $LP_{saa}$,
and so it is safe to remove them and reduce the size of the LP. This is borne out from our experiments.
\end{itemize}
